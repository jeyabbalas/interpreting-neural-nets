{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELI5 library\n",
    "Available methods--\n",
    "1. Permutation Importance: Feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model to interpret\n",
    "1. ELI5 library only works for sklearn models, so Keras models have to be wrapped as sklearn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# For data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# For interpreting the model\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "bc_data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(bc_data.data, bc_data.target,\n",
    "                                                   test_size=0.25, random_state=1)\n",
    "feature_names = bc_data.feature_names\n",
    "\n",
    "# Normalizing the predictive variables\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a MLP classification model with Keras API\n",
    "def build_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=[30]),\n",
    "        keras.layers.Dense(30, activation='relu'),\n",
    "        keras.layers.Dense(30, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=keras.optimizers.Adam(),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping Keras model with a thin sklearn wrapper\n",
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model learning\n",
    "history = keras_clf.fit(X_train, y_train,\n",
    "             batch_size=32, epochs=100, verbose=0,\n",
    "             validation_data=(X_test, y_test),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance\n",
    "1. Computes feature importance of each variable in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 32us/sample - loss: 0.1028 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1303 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1262 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1069 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1162 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1229 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0914 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0815 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 34us/sample - loss: 0.1028 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0899 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1042 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 34us/sample - loss: 0.1439 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0957 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1074 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0828 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1088 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1701 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1094 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1122 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 42us/sample - loss: 0.1387 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1312 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1018 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1400 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0950 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1540 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1438 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1052 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1301 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0882 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1125 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1065 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0952 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1218 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 34us/sample - loss: 0.0770 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1198 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1356 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1239 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1493 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1183 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1041 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1073 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1410 - accuracy: 0.9371\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1004 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0973 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.0954 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1095 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1123 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1083 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 42us/sample - loss: 0.1078 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1037 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1027 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1274 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1229 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1223 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1999 - accuracy: 0.9371\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1294 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1066 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1325 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1140 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1418 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1383 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1211 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1529 - accuracy: 0.9371\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1130 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0865 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1219 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0826 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1434 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1057 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 34us/sample - loss: 0.1062 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0894 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1798 - accuracy: 0.9301\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0967 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1003 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 34us/sample - loss: 0.0796 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 42us/sample - loss: 0.1023 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1192 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 43us/sample - loss: 0.1118 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1006 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0953 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 42us/sample - loss: 0.1176 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1143 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 81us/sample - loss: 0.1552 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1090 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1649 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1338 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1033 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1156 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1008 - accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0964 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1082 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 81us/sample - loss: 0.1105 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1394 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1026 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0977 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1083 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0951 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1320 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1173 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0892 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 80us/sample - loss: 0.1114 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1814 - accuracy: 0.9371\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0885 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0896 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0937 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1030 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1310 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1086 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1075 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 80us/sample - loss: 0.1239 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1040 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1181 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1380 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0970 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1180 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1209 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1057 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1167 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 80us/sample - loss: 0.0942 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 34us/sample - loss: 0.1401 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1062 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0889 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1173 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1202 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1201 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1202 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 45us/sample - loss: 0.1028 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 83us/sample - loss: 0.1193 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 42us/sample - loss: 0.1033 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0979 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1010 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1405 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0995 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0939 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0930 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 43us/sample - loss: 0.1036 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 86us/sample - loss: 0.1818 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1066 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0974 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1146 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 45us/sample - loss: 0.1256 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0809 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1379 - accuracy: 0.9371\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1222 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1267 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 82us/sample - loss: 0.1355 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1095 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1379 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0704 - accuracy: 0.9860\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0901 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1101 - accuracy: 0.9720\n"
     ]
    }
   ],
   "source": [
    "# Learning variable importance using Permutation analysis\n",
    "perm_obj = PermutationImportance(keras_clf, random_state=1).fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0252\n",
       "                \n",
       "                    &plusmn; 0.0143\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                radius error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0224\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean texture\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0126\n",
       "                \n",
       "                    &plusmn; 0.0186\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst texture\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0126\n",
       "                \n",
       "                    &plusmn; 0.0163\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst area\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0069\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean smoothness\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0069\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst smoothness\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0206\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst concavity\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0105\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                symmetry error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst radius\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0153\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean perimeter\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0088\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                area error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0088\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst symmetry\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0056\n",
       "                \n",
       "                    &plusmn; 0.0163\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                compactness error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0056\n",
       "                \n",
       "                    &plusmn; 0.0206\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean concavity\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0056\n",
       "                \n",
       "                    &plusmn; 0.0206\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst perimeter\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "                    &plusmn; 0.0143\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fractal dimension error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0224\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean radius\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0137\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean concave points\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0125\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean area\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0088\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst fractal dimension\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 10 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View variable importance\n",
    "eli5.show_weights(perm_obj, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "1. Some variables have a negative score. Could have happened by chance where the permutation led to a better set of predictions\n",
    "2. Can be used for feature selection (https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html#feature-selection)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
