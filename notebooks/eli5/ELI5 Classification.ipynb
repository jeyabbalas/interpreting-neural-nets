{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELI5 library\n",
    "\n",
    "## Building a model to interpret\n",
    "1. ELI5 library only works for sklearn models, so Keras models have to be wrapped as sklearn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# For data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# For interpreting the model\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "bc_data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(bc_data.data, bc_data.target,\n",
    "                                                   test_size=0.25, random_state=1)\n",
    "feature_names = bc_data.feature_names\n",
    "\n",
    "# Normalizing the predictive variables\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a MLP classification model with Keras API\n",
    "def build_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=[30]),\n",
    "        keras.layers.Dense(30, activation='relu'),\n",
    "        keras.layers.Dense(30, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=keras.optimizers.Adam(),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping Keras model with a thin sklearn wrapper\n",
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model learning\n",
    "history = keras_clf.fit(X_train, y_train,\n",
    "             batch_size=32, epochs=100, verbose=0,\n",
    "             validation_data=(X_test, y_test),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance\n",
    "1. Computes feature importance of each variable in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 34us/sample - loss: 0.0935 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1001 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1161 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1008 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0932 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0966 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.0908 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0732 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0981 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0902 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 79us/sample - loss: 0.0906 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1166 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0937 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0929 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0779 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0942 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1598 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0814 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0981 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1206 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0973 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0882 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1092 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1015 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1439 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1416 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0817 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1042 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 78us/sample - loss: 0.0865 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0922 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0901 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.0823 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1012 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0633 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0923 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 34us/sample - loss: 0.0978 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 43us/sample - loss: 0.0919 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 81us/sample - loss: 0.1355 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0976 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0850 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0849 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1123 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 43us/sample - loss: 0.0907 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0874 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0904 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0936 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 75us/sample - loss: 0.1064 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0887 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1012 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0971 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0964 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1051 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1030 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1491 - accuracy: 0.9301\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1691 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 76us/sample - loss: 0.1371 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0894 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0910 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1037 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0999 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1005 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0916 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1220 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1153 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.0954 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1018 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0921 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 45us/sample - loss: 0.1192 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1063 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0793 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0781 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1546 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0948 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0930 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0768 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0780 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1079 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.0976 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0924 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0879 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.0889 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0977 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 85us/sample - loss: 0.1253 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1406 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 43us/sample - loss: 0.1392 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1487 - accuracy: 0.9441\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0954 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 42us/sample - loss: 0.1082 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 44us/sample - loss: 0.0900 - accuracy: 0.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 42us/sample - loss: 0.0939 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 42us/sample - loss: 0.0974 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 84us/sample - loss: 0.0846 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1391 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.0878 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0972 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0987 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1056 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1099 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 44us/sample - loss: 0.1053 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1022 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 94us/sample - loss: 0.0898 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1362 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0967 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 42us/sample - loss: 0.0907 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0976 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 44us/sample - loss: 0.0944 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1288 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1003 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 46us/sample - loss: 0.1028 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 85us/sample - loss: 0.0989 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0968 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0958 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1150 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1242 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0930 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1526 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0989 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0896 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 82us/sample - loss: 0.0940 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1058 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0931 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0817 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1043 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.1157 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0958 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.1034 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.1008 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 78us/sample - loss: 0.0943 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1030 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 34us/sample - loss: 0.0835 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0926 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1283 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0932 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0892 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0832 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0927 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 78us/sample - loss: 0.1494 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.1016 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 35us/sample - loss: 0.0886 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.1015 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 44us/sample - loss: 0.1024 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 37us/sample - loss: 0.0820 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.1112 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 44us/sample - loss: 0.1299 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 40us/sample - loss: 0.1153 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 83us/sample - loss: 0.1335 - accuracy: 0.9510\n",
      "143/143 [==============================] - 0s 36us/sample - loss: 0.0832 - accuracy: 0.9720\n",
      "143/143 [==============================] - 0s 41us/sample - loss: 0.0942 - accuracy: 0.9650\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0686 - accuracy: 0.9790\n",
      "143/143 [==============================] - 0s 39us/sample - loss: 0.0907 - accuracy: 0.9580\n",
      "143/143 [==============================] - 0s 38us/sample - loss: 0.0910 - accuracy: 0.9650\n"
     ]
    }
   ],
   "source": [
    "# Learning variable importance using Permutation analysis\n",
    "perm_obj = PermutationImportance(keras_clf, random_state=1).fit(X_test, y_test, \n",
    "                                                            verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0154\n",
       "                \n",
       "                    &plusmn; 0.0105\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                radius error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0154\n",
       "                \n",
       "                    &plusmn; 0.0105\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst smoothness\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0126\n",
       "                \n",
       "                    &plusmn; 0.0285\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst perimeter\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0153\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean concavity\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0125\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst area\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0088\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                compactness error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean smoothness\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.15%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0056\n",
       "                \n",
       "                    &plusmn; 0.0105\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean perimeter\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.95%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "                    &plusmn; 0.0069\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst symmetry\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0028\n",
       "                \n",
       "                    &plusmn; 0.0112\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst texture\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                perimeter error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                concavity error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean area\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean concave points\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst fractal dimension\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst radius\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0088\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst concavity\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                texture error\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                mean compactness\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0014\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                worst compactness\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.27%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 10 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View variable importance\n",
    "eli5.show_weights(perm_obj, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "1. Some variables have a negative score. Could have happened by chance where the permutation led to a better set of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
