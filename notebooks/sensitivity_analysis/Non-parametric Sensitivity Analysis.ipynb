{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# For data\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdf(x):\n",
    "    \"\"\"\n",
    "    Computes cumulative distribution function for the input vector.\n",
    "    Input窶能n",
    "        x: data vector\n",
    "    Output窶能n",
    "        cdf: cumulative distribution function\n",
    "    \"\"\"\n",
    "    n = x.size\n",
    "    x_indices_sorted = np.argsort(x, kind='mergesort') # Warning: ties have different ranks.\n",
    "    x_sorted = x[x_indices_sorted]\n",
    "    x_sorted_cdf = np.array(list(range(n)))/(n-1)\n",
    "    cdf = np.stack((x_sorted, x_sorted_cdf))\n",
    "    \n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_point_to_linear_interp(x_val, memb):\n",
    "    X = memb[0,:]\n",
    "    Y = memb[1,:]\n",
    "    i = np.sum(X < x_val) # index of first X value > x_val\n",
    "    n = Y.size\n",
    "    \n",
    "    if(i == 0): # lower bound\n",
    "        return Y[0]\n",
    "    elif(i == n): # upper bound\n",
    "        return Y[n - 1] \n",
    "    else: # y = b + m*x\n",
    "        return (Y[i-1] + ((Y[i] - Y[i-1])/(X[i] - X[i-1]))*(x_val - X[i-1]))\n",
    "\n",
    "def map_data_to_linear_interp(x, memb):\n",
    "    \"\"\"\n",
    "    Map each value of vector x according to the linear function\n",
    "    interpolated between the points specified by the membership function.\n",
    "    Input窶能n",
    "        x: input vector of values\n",
    "    Output窶能n",
    "        memb: distribution specified by two rows. Row 1 contains\n",
    "            the raw x values. Row 2 contains the membership of the\n",
    "            raw x values.\n",
    "    \"\"\"\n",
    "    return np.array([map_point_to_linear_interp(x_val, memb) for x_val in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_transform_fit(data):\n",
    "    cdfs = list()\n",
    "    for i in range(data.shape[1]):\n",
    "        cdfs.append(get_cdf(data[:,i]))\n",
    "    return cdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_transform(data, cdfs):\n",
    "    norm_data = np.zeros((data.shape[0], data.shape[1]), dtype=float)\n",
    "    for i in range(data.shape[1]):\n",
    "        norm_data[:,i] = map_data_to_linear_interp(data[:,i], cdfs[i])\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "\n",
    "X = iris_data.data\n",
    "y = (iris_data.target==0).astype(int) # is setosa?\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "feature_names = iris_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = rank_transform_fit(X_train)\n",
    "norm_X_train = rank_transform(X_train, cdfs)\n",
    "norm_X_test = rank_transform(X_test, cdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "mms_X_train = scaler.transform(X_train)\n",
    "mms_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[X_train.shape[1]]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "    \n",
    "model_old.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old2 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[X_train.shape[1]]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "    \n",
    "model_old2.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[X_train.shape[1]]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a root log directory\n",
    "import os\n",
    "import time\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./my_logs/run_2020_03_09-07_05_27\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/200\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.6403 - accuracy: 0.3393 - val_loss: 0.5804 - val_accuracy: 0.8947\n",
      "Epoch 2/200\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.5696 - accuracy: 0.9375 - val_loss: 0.5182 - val_accuracy: 0.9737\n",
      "Epoch 3/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.5106 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.4613 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.4171 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.3783 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.3431 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.3107 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.2545 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.2297 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.1871 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.1688 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.1521 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.1373 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.1121 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "112/112 [==============================] - 0s 186us/sample - loss: 0.0921 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "112/112 [==============================] - 0s 198us/sample - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "112/112 [==============================] - 0s 198us/sample - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 163us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "112/112 [==============================] - 0s 176us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 164us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 9.9089e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 9.7905e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 9.6689e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 9.5618e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 9.4330e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 9.3272e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 9.2235e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 9.1251e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 9.0233e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 8.9099e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 8.8243e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 8.7227e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 8.6306e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 8.5382e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 8.4522e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 8.3612e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 8.2661e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 8.1768e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 8.0975e-04 - accuracy: 1.0000 - val_loss: 9.9431e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 8.0025e-04 - accuracy: 1.0000 - val_loss: 9.8803e-04 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 7.9223e-04 - accuracy: 1.0000 - val_loss: 9.7987e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 7.8350e-04 - accuracy: 1.0000 - val_loss: 9.7503e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 7.7545e-04 - accuracy: 1.0000 - val_loss: 9.7180e-04 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "112/112 [==============================] - 0s 202us/sample - loss: 7.6760e-04 - accuracy: 1.0000 - val_loss: 9.6526e-04 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 7.6042e-04 - accuracy: 1.0000 - val_loss: 9.5235e-04 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 7.5120e-04 - accuracy: 1.0000 - val_loss: 9.4260e-04 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 7.4344e-04 - accuracy: 1.0000 - val_loss: 9.3233e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Old Model learning\n",
    "history = model_old.fit(X_train, y_train,\n",
    "             batch_size=32, epochs=200, verbose=1,\n",
    "             validation_data=(X_test, y_test),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                       keras.callbacks.TensorBoard(run_logdir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 106us/sample - loss: 9.3233e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0009323289789455501, 1.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_old.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./my_logs/run_2020_03_09-10_37_16\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/200\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.6800 - accuracy: 0.6250 - val_loss: 0.6627 - val_accuracy: 0.6579\n",
      "Epoch 2/200\n",
      "112/112 [==============================] - 0s 111us/sample - loss: 0.6520 - accuracy: 0.6696 - val_loss: 0.6377 - val_accuracy: 0.6579\n",
      "Epoch 3/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.6261 - accuracy: 0.6696 - val_loss: 0.6168 - val_accuracy: 0.6579\n",
      "Epoch 4/200\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.6027 - accuracy: 0.6696 - val_loss: 0.5974 - val_accuracy: 0.6579\n",
      "Epoch 5/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.5815 - accuracy: 0.6696 - val_loss: 0.5781 - val_accuracy: 0.6579\n",
      "Epoch 6/200\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.5599 - accuracy: 0.6696 - val_loss: 0.5590 - val_accuracy: 0.6579\n",
      "Epoch 7/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.5398 - accuracy: 0.6696 - val_loss: 0.5403 - val_accuracy: 0.6579\n",
      "Epoch 8/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.5203 - accuracy: 0.6696 - val_loss: 0.5231 - val_accuracy: 0.6579\n",
      "Epoch 9/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.5027 - accuracy: 0.6696 - val_loss: 0.5069 - val_accuracy: 0.6579\n",
      "Epoch 10/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.4861 - accuracy: 0.6696 - val_loss: 0.4909 - val_accuracy: 0.6579\n",
      "Epoch 11/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.4700 - accuracy: 0.6696 - val_loss: 0.4752 - val_accuracy: 0.6579\n",
      "Epoch 12/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.4545 - accuracy: 0.6696 - val_loss: 0.4596 - val_accuracy: 0.6579\n",
      "Epoch 13/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.4393 - accuracy: 0.6696 - val_loss: 0.4439 - val_accuracy: 0.6579\n",
      "Epoch 14/200\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.4238 - accuracy: 0.6696 - val_loss: 0.4278 - val_accuracy: 0.6579\n",
      "Epoch 15/200\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.4081 - accuracy: 0.6696 - val_loss: 0.4109 - val_accuracy: 0.6579\n",
      "Epoch 16/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.3918 - accuracy: 0.6696 - val_loss: 0.3931 - val_accuracy: 0.6579\n",
      "Epoch 17/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.3748 - accuracy: 0.7143 - val_loss: 0.3748 - val_accuracy: 0.7368\n",
      "Epoch 18/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.3573 - accuracy: 0.8304 - val_loss: 0.3564 - val_accuracy: 0.9211\n",
      "Epoch 19/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.3400 - accuracy: 0.9196 - val_loss: 0.3372 - val_accuracy: 0.9474\n",
      "Epoch 20/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.3215 - accuracy: 0.9821 - val_loss: 0.3175 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.3037 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.2853 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2682 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.2521 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2358 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.2055 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.1913 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.1772 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.1643 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.1519 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.1404 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.1187 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.1095 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.1006 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "112/112 [==============================] - 0s 182us/sample - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 164us/sample - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "112/112 [==============================] - 0s 183us/sample - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "112/112 [==============================] - 0s 199us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "112/112 [==============================] - 0s 175us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.8904e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.7548e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.5929e-04 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.4383e-04 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.3139e-04 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.1889e-04 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.0354e-04 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.8771e-04 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.7256e-04 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.5764e-04 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.4552e-04 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.3248e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.2155e-04 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.1108e-04 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.9875e-04 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.8891e-04 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.7920e-04 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.7156e-04 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.6279e-04 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.5179e-04 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.4031e-04 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.2887e-04 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.1890e-04 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.0893e-04 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.9870e-04 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 9.9502e-04 - accuracy: 1.0000 - val_loss: 6.8874e-04 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 9.8161e-04 - accuracy: 1.0000 - val_loss: 6.7923e-04 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 9.7002e-04 - accuracy: 1.0000 - val_loss: 6.7021e-04 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 9.5744e-04 - accuracy: 1.0000 - val_loss: 6.6165e-04 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 9.4508e-04 - accuracy: 1.0000 - val_loss: 6.5491e-04 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 9.3452e-04 - accuracy: 1.0000 - val_loss: 6.4565e-04 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 9.2117e-04 - accuracy: 1.0000 - val_loss: 6.3714e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 9.1030e-04 - accuracy: 1.0000 - val_loss: 6.2899e-04 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 8.9938e-04 - accuracy: 1.0000 - val_loss: 6.2000e-04 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 8.8788e-04 - accuracy: 1.0000 - val_loss: 6.1408e-04 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 8.7639e-04 - accuracy: 1.0000 - val_loss: 6.0636e-04 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 8.6580e-04 - accuracy: 1.0000 - val_loss: 5.9915e-04 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 8.5554e-04 - accuracy: 1.0000 - val_loss: 5.9100e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 8.4528e-04 - accuracy: 1.0000 - val_loss: 5.8330e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 8.3493e-04 - accuracy: 1.0000 - val_loss: 5.7617e-04 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 8.2506e-04 - accuracy: 1.0000 - val_loss: 5.6822e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 8.1459e-04 - accuracy: 1.0000 - val_loss: 5.6147e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 8.0598e-04 - accuracy: 1.0000 - val_loss: 5.5593e-04 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 7.9608e-04 - accuracy: 1.0000 - val_loss: 5.5002e-04 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 7.8592e-04 - accuracy: 1.0000 - val_loss: 5.4407e-04 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 7.7683e-04 - accuracy: 1.0000 - val_loss: 5.3802e-04 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 7.6870e-04 - accuracy: 1.0000 - val_loss: 5.3354e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Old Model learning -MinMaxScaler\n",
    "history = model_old2.fit(mms_X_train, y_train,\n",
    "             batch_size=32, epochs=200, verbose=1,\n",
    "             validation_data=(mms_X_test, y_test),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                       keras.callbacks.TensorBoard(run_logdir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 91us/sample - loss: 5.3354e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0005335431702214441, 1.0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_old2.evaluate(mms_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./my_logs/run_2020_03_09-07_06_09\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/200\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.6707 - accuracy: 0.6696 - val_loss: 0.6657 - val_accuracy: 0.6579\n",
      "Epoch 2/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.6469 - accuracy: 0.6696 - val_loss: 0.6428 - val_accuracy: 0.6579\n",
      "Epoch 3/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.6231 - accuracy: 0.6696 - val_loss: 0.6218 - val_accuracy: 0.6579\n",
      "Epoch 4/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.6013 - accuracy: 0.6696 - val_loss: 0.6026 - val_accuracy: 0.6579\n",
      "Epoch 5/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.5808 - accuracy: 0.6696 - val_loss: 0.5843 - val_accuracy: 0.6579\n",
      "Epoch 6/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.5616 - accuracy: 0.6696 - val_loss: 0.5658 - val_accuracy: 0.6579\n",
      "Epoch 7/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.5426 - accuracy: 0.6696 - val_loss: 0.5468 - val_accuracy: 0.6579\n",
      "Epoch 8/200\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.5230 - accuracy: 0.6696 - val_loss: 0.5271 - val_accuracy: 0.6579\n",
      "Epoch 9/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.5024 - accuracy: 0.6696 - val_loss: 0.5070 - val_accuracy: 0.6579\n",
      "Epoch 10/200\n",
      "112/112 [==============================] - 0s 191us/sample - loss: 0.4822 - accuracy: 0.6696 - val_loss: 0.4870 - val_accuracy: 0.6579\n",
      "Epoch 11/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.4625 - accuracy: 0.6696 - val_loss: 0.4668 - val_accuracy: 0.6579\n",
      "Epoch 12/200\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.4422 - accuracy: 0.6696 - val_loss: 0.4464 - val_accuracy: 0.6842\n",
      "Epoch 13/200\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.4217 - accuracy: 0.6964 - val_loss: 0.4254 - val_accuracy: 0.6842\n",
      "Epoch 14/200\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.4014 - accuracy: 0.7500 - val_loss: 0.4038 - val_accuracy: 0.7368\n",
      "Epoch 15/200\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.3815 - accuracy: 0.8482 - val_loss: 0.3822 - val_accuracy: 0.8684\n",
      "Epoch 16/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.3614 - accuracy: 0.9107 - val_loss: 0.3611 - val_accuracy: 0.9211\n",
      "Epoch 17/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.3420 - accuracy: 0.9286 - val_loss: 0.3404 - val_accuracy: 0.9474\n",
      "Epoch 18/200\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.3235 - accuracy: 0.9375 - val_loss: 0.3205 - val_accuracy: 0.9737\n",
      "Epoch 19/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.3056 - accuracy: 0.9554 - val_loss: 0.3017 - val_accuracy: 0.9737\n",
      "Epoch 20/200\n",
      "112/112 [==============================] - 0s 180us/sample - loss: 0.2891 - accuracy: 0.9643 - val_loss: 0.2839 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.2732 - accuracy: 0.9732 - val_loss: 0.2673 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.2582 - accuracy: 0.9732 - val_loss: 0.2516 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.2445 - accuracy: 0.9821 - val_loss: 0.2365 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.2306 - accuracy: 0.9911 - val_loss: 0.2215 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.2167 - accuracy: 0.9911 - val_loss: 0.2068 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.2035 - accuracy: 0.9911 - val_loss: 0.1922 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.1909 - accuracy: 0.9911 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.1779 - accuracy: 0.9911 - val_loss: 0.1647 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.1658 - accuracy: 0.9911 - val_loss: 0.1517 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.1543 - accuracy: 0.9911 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.1430 - accuracy: 0.9911 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.1326 - accuracy: 0.9911 - val_loss: 0.1171 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.1228 - accuracy: 0.9911 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.1137 - accuracy: 0.9911 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "112/112 [==============================] - 0s 192us/sample - loss: 0.1053 - accuracy: 0.9911 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.0974 - accuracy: 0.9911 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.0902 - accuracy: 0.9911 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.0839 - accuracy: 0.9911 - val_loss: 0.0683 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "112/112 [==============================] - 0s 201us/sample - loss: 0.0777 - accuracy: 0.9911 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.0726 - accuracy: 0.9911 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.0677 - accuracy: 0.9911 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0632 - accuracy: 0.9911 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0590 - accuracy: 0.9911 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.0555 - accuracy: 0.9911 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0521 - accuracy: 0.9911 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "112/112 [==============================] - 0s 188us/sample - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "112/112 [==============================] - 0s 181us/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "112/112 [==============================] - 0s 167us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "112/112 [==============================] - 0s 165us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "112/112 [==============================] - 0s 169us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "112/112 [==============================] - 0s 160us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "112/112 [==============================] - 0s 172us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 9.9656e-04 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 9.7849e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 9.6358e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 9.4800e-04 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 9.3166e-04 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 9.1535e-04 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 8.9765e-04 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 8.7875e-04 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 8.6064e-04 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 8.4477e-04 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 8.3039e-04 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 8.1569e-04 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 8.0216e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 7.8970e-04 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 7.7637e-04 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.6410e-04 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.5073e-04 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.3688e-04 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.2439e-04 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.1208e-04 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.9988e-04 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.8857e-04 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.7857e-04 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.6708e-04 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.5661e-04 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.4649e-04 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.3602e-04 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.2551e-04 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.1530e-04 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.0577e-04 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.9641e-04 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.8773e-04 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.7916e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 141us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.7048e-04 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.6183e-04 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.5448e-04 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.4692e-04 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "112/112 [==============================] - 0s 190us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.3955e-04 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.3160e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.2390e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.1557e-04 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.0818e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.0075e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.9389e-04 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.8681e-04 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.8047e-04 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.7382e-04 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.6775e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# New Model learning\n",
    "history = model.fit(norm_X_train, y_train,\n",
    "             batch_size=32, epochs=200, verbose=1,\n",
    "             validation_data=(norm_X_test, y_test),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10),\n",
    "                       keras.callbacks.TensorBoard(run_logdir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 96us/sample - loss: 4.6775e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0004677487472930041, 1.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(norm_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 61765), started 0:10:14 ago. (Use '!kill 61765' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dfe069fdd1494557\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dfe069fdd1494557\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 10\n",
    "\n",
    "fig, [[ax0, ax1], [ax2, ax3]] = plt.subplots(2, 2, figsize=(10,5))\n",
    "fig.suptitle('Histograms of raw data')\n",
    "n, bins, patches = ax0.hist(X_train[:,0], num_bins, density=1)\n",
    "ax0.set_xlabel('Sepal length (cm)')\n",
    "n, bins, patches = ax1.hist(X_train[:,1], num_bins, density=1)\n",
    "ax1.set_xlabel('Sepal width (cm)')\n",
    "n, bins, patches = ax2.hist(X_train[:,2], num_bins, density=1)\n",
    "ax2.set_xlabel('Petal length (cm)')\n",
    "n, bins, patches = ax3.hist(X_train[:,3], num_bins, density=1)\n",
    "ax3.set_xlabel('Petal width (cm)')\n",
    "fig.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 10\n",
    "\n",
    "fig, [[ax0, ax1], [ax2, ax3]] = plt.subplots(2, 2, figsize=(10,5))\n",
    "fig.suptitle('Histograms of rank transformed data')\n",
    "n, bins, patches = ax0.hist(norm_X_train[:,0], num_bins, density=1)\n",
    "ax0.set_xlabel('Sepal length')\n",
    "n, bins, patches = ax1.hist(norm_X_train[:,1], num_bins, density=1)\n",
    "ax1.set_xlabel('Sepal width')\n",
    "n, bins, patches = ax2.hist(norm_X_train[:,2], num_bins, density=1)\n",
    "ax2.set_xlabel('Petal length')\n",
    "n, bins, patches = ax3.hist(norm_X_train[:,3], num_bins, density=1)\n",
    "ax3.set_xlabel('Petal width')\n",
    "fig.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train[:,2], X_train[:,3])\n",
    "plt.title('Raw data')\n",
    "plt.xlabel('Petal length (cm)')\n",
    "plt.ylabel('Petal width (cm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gaps because of poor handling of ties\n",
    "plt.scatter(norm_X_train[:,2], norm_X_train[:,3], color='r')\n",
    "plt.title('Raw data')\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.1, 1.3, 1.3, 1.3, 1.3, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4,\n",
       "       1.4, 1.4, 1.4, 1.4, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5,\n",
       "       1.5, 1.6, 1.6, 1.6, 1.6, 1.6, 1.6, 1.7, 1.7, 1.7, 1.9, 3.3, 3.3,\n",
       "       3.5, 3.5, 3.6, 3.7, 3.8, 3.9, 3.9, 4. , 4. , 4. , 4.1, 4.1, 4.2,\n",
       "       4.2, 4.2, 4.3, 4.3, 4.4, 4.4, 4.5, 4.5, 4.5, 4.5, 4.6, 4.6, 4.7,\n",
       "       4.7, 4.7, 4.8, 4.8, 4.8, 4.8, 4.9, 4.9, 4.9, 4.9, 4.9, 5. , 5. ,\n",
       "       5.1, 5.1, 5.1, 5.1, 5.1, 5.1, 5.2, 5.2, 5.3, 5.3, 5.4, 5.4, 5.5,\n",
       "       5.5, 5.5, 5.6, 5.6, 5.6, 5.6, 5.6, 5.7, 5.7, 5.8, 5.8, 5.8, 5.9,\n",
       "       6. , 6.1, 6.1, 6.3, 6.6, 6.7, 6.7, 6.9])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(X_train[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Variable Importance using Sensitivity Analysis\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. The Jacobian ($\\pmb{J}$) is the partial derivative of the of the outcome variable ($y$) with respect to each rank transformed input variable ($x_i; \\text{ where } i=1,\\cdots, n$).\n",
    "\n",
    "$$\n",
    "\\pmb{J}_{\\vec{x}} = \\left[\\frac{\\partial f(\\vec{x})}{\\partial x_{1}}\\;\\;\\;\\;\\;\\; \\frac{\\partial f(\\vec{x})}{\\partial x_{2}}\\;\\; \\cdots\\;\\; \\frac{\\partial f(\\vec{x})}{\\partial x_{n}} \\right]\n",
    "$$\n",
    "\n",
    "2. Compute the absolute value of the Jacobian for all the instances in the training dataset ($D^{train}$). This corresponds to the variable importance of each predictor variable according to the model induced from the training dataset.\n",
    "\n",
    "$$\n",
    "VarImp = \\frac{1}{|D^{train}|}\\sum_{\\vec{x} \\in D^{train}} |\\pmb{J}_{\\vec{x}}|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_jacobian_1output(x, model):\n",
    "    \"\"\"\n",
    "    Computes the Jacobian of an input vector and \n",
    "    a Keras model with a single output node.\n",
    "    \n",
    "    Input窶能n",
    "    x: Floating numpy vector of inputs.\n",
    "    model: Keras model.\n",
    "    \n",
    "    Output窶能n",
    "    jacobian: Absolute numpy Jacobian vector for \n",
    "        scalar output wrt each input.\n",
    "    \"\"\"\n",
    "    x_tensor = tf.convert_to_tensor(x.reshape(1,-1), dtype=tf.float32)\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(x_tensor)\n",
    "        y_tensor = model(x_tensor)\n",
    "    jacobian = g.jacobian(y_tensor, x_tensor)\n",
    "    jacobian = jacobian.numpy()[0][0][0]\n",
    "    \n",
    "    return np.absolute(jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_importance_sensitivity_analysis(data, model):\n",
    "    \"\"\"\n",
    "    Computes variable importance of each input variable using sensitivity analysis.\n",
    "    \n",
    "    Input窶能n",
    "    data: Data as a numpy matrix.\n",
    "    model: Keras model.\n",
    "    \n",
    "    Output窶能n",
    "    variable_importance: average absolute gradient wrt each input over all instances\n",
    "    of 'data'.\n",
    "    \"\"\"\n",
    "    abs_jacobian = np.apply_along_axis(abs_jacobian_1output,\n",
    "                       1,\n",
    "                       data, model=model)\n",
    "    sum_jacobian = np.sum(abs_jacobian, axis=0)\n",
    "    \n",
    "    return sum_jacobian/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_adimensional_jacobian_1output_old(x, model):\n",
    "    \"\"\"\n",
    "    Computes the adimensional Jacobian of an input vector and \n",
    "    a Keras model with a single output node.\n",
    "    \n",
    "    Input窶能n",
    "    x: Floating numpy vector of inputs.\n",
    "    model: Keras model.\n",
    "    \n",
    "    Output窶能n",
    "    jacobian: Absolute adimensional numpy Jacobian vector for \n",
    "        scalar output wrt each input.\n",
    "    \"\"\"\n",
    "    x_tensor = tf.convert_to_tensor(x.reshape(1,-1), dtype=tf.float32)\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(x_tensor)\n",
    "        y_tensor = model(x_tensor)\n",
    "    jacobian = g.jacobian(y_tensor, x_tensor)\n",
    "    jacobian = jacobian.numpy()[0][0][0]\n",
    "    \n",
    "    # Hadamard product between input-variable-gradient and \n",
    "    # variable-value/loss to remove the dimensions\n",
    "    input_by_loss = x/y_tensor.numpy()[0][0]\n",
    "    adim_jacobian = np.multiply(jacobian, input_by_loss)\n",
    "    \n",
    "    return np.absolute(adim_jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_importance_sensitivity_analysis_old(data, model):\n",
    "    \"\"\"\n",
    "    Computes variable importance of each input variable using sensitivity analysis.\n",
    "    \n",
    "    Input窶能n",
    "    data: Data as a numpy matrix.\n",
    "    model: Keras model.\n",
    "    \n",
    "    Output窶能n",
    "    variable_importance: average absolute gradient wrt each input over all instances\n",
    "    of 'data'.\n",
    "    \"\"\"\n",
    "    abs_jacobian = np.apply_along_axis(abs_adimensional_jacobian_1output_old,\n",
    "                       1,\n",
    "                       data, model=model)\n",
    "    sum_jacobian = np.sum(abs_jacobian, axis=0)\n",
    "    \n",
    "    return sum_jacobian/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = variable_importance_sensitivity_analysis(norm_X_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01562984, 0.01675144, 0.01788494, 0.01139934], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With rank transformation\n",
    "var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_old = variable_importance_sensitivity_analysis_old(X_train, model_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41839205, 1.5823931 , 3.79978242, 0.77141107])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw inputs\n",
    "var_imp_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_old2 = variable_importance_sensitivity_analysis_old(mms_X_train, model_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10686272, 0.14056886, 0.41952085, 0.19803721])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With min-max scaling\n",
    "var_imp_old2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = variable_importance_sensitivity_analysis_old(norm_X_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.55622709, 1.01347387, 3.21254169, 1.96554852])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplying with odds ratio\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
